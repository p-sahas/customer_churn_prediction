name: ml-pipeline

services:
  mlflow-tracking:
    build:
      context: .
      dockerfile: docker/mlflow-tracking/Dockerfile
    image: mlflow-tracking:latest
    container_name: mlflow-tracking
    ports:
      - "5001:5001"
    environment:
      - AWS_REGION=${AWS_REGION:-ap-south-1}
      - AWS_SHARED_CREDENTIALS_FILE=/aws/credentials
      - AWS_CONFIG_FILE=/aws/config
      - AWS_PROFILE=${AWS_PROFILE:-default}
      - MLFLOW_BACKEND_STORE_URI=file:///tmp/mlruns
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://${S3_BUCKET:-zuucrew-mlflow-artifacts-prod}/mlflow-artifacts
    volumes:
      - ~/.aws:/aws:ro
    networks:
      - ml-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  data-pipeline:
    build:
      context: .
      dockerfile: docker/data-pipeline/Dockerfile
      args:
        UID: 1001
        GID: 1001
    image: data-pipeline:latest
    container_name: data-pipeline
    environment:
      - HOME=/home/appuser
      - SPARK_LOCAL_DIRS=/tmp/spark
      - HADOOP_OPTS=-Djava.io.tmpdir=/tmp/hadoop
      - AWS_REGION=${AWS_REGION:-ap-south-1}
      - AWS_SHARED_CREDENTIALS_FILE=/aws/credentials
      - AWS_CONFIG_FILE=/aws/config
      - AWS_PROFILE=${AWS_PROFILE:-default}
      - S3_BUCKET=${S3_BUCKET:-zuucrew-mlflow-artifacts-prod}
      - MLFLOW_TRACKING_URI=http://mlflow-tracking:5001
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    volumes:
      - ~/.aws:/aws:ro
    networks:
      - ml-net
    depends_on:
      mlflow-tracking:
        condition: service_healthy
    restart: "no"
    profiles:
      - data

  model-pipeline:
    build:
      context: .
      dockerfile: docker/model-pipeline/Dockerfile
      args:
        UID: 1001
        GID: 1001
    image: model-pipeline:latest
    container_name: model-pipeline
    environment:
      - HOME=/home/appuser
      - SPARK_LOCAL_DIRS=/tmp/spark
      - HADOOP_OPTS=-Djava.io.tmpdir=/tmp/hadoop
      - AWS_REGION=${AWS_REGION:-ap-south-1}
      - AWS_SHARED_CREDENTIALS_FILE=/aws/credentials
      - AWS_CONFIG_FILE=/aws/config
      - AWS_PROFILE=${AWS_PROFILE:-default}
      - S3_BUCKET=${S3_BUCKET:-zuucrew-mlflow-artifacts-prod}
      - MLFLOW_TRACKING_URI=http://mlflow-tracking:5001
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    volumes:
      - ~/.aws:/aws:ro
    networks:
      - ml-net
    depends_on:
      mlflow-tracking:
        condition: service_healthy
    restart: "no"
    profiles:
      - model

  inference-pipeline:
    build:
      context: .
      dockerfile: docker/inference-pipeline/Dockerfile
      args:
        UID: 1001
        GID: 1001
    image: inference-pipeline:latest
    container_name: inference-pipeline
    environment:
      - HOME=/home/appuser
      - SPARK_LOCAL_DIRS=/tmp/spark
      - HADOOP_OPTS=-Djava.io.tmpdir=/tmp/hadoop
      - AWS_REGION=${AWS_REGION:-ap-south-1}
      - AWS_SHARED_CREDENTIALS_FILE=/aws/credentials
      - AWS_CONFIG_FILE=/aws/config
      - AWS_PROFILE=${AWS_PROFILE:-default}
      - S3_BUCKET=${S3_BUCKET:-zuucrew-mlflow-artifacts-prod}
      - MLFLOW_TRACKING_URI=http://mlflow-tracking:5001
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    volumes:
      - ~/.aws:/aws:ro
    networks:
      - ml-net
    depends_on:
      mlflow-tracking:
        condition: service_healthy
    restart: "no"
    profiles:
      - inference

networks:
  ml-net:
    driver: bridge
    name: ml-pipeline-network

volumes:
  mlflow-db:
    driver: local
    name: mlflow-database
